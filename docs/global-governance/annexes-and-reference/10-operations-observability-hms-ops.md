# Chapter 10: Operations & Observability (HMS-OPS)

*(Jumped in from [Financial Transaction Engine (HMS-ACH)](09_financial_transaction_engine__hms_ach__.md))*  

---

## 1 â€” Why Does HMS Need a â€œControl Towerâ€?

Imagine 9 PM on a Friday.  
HUD has just queued **10,000 emergency payments** in [HMS-ACH](09_financial_transaction_engine__hms_ach__.md).  
Suddenly â€” latency to the Federal Reserve rail jumps from **200 ms to 12 s**.

If nobody notices:

* ACH files miss the nightly cutoff â†’ citizens donâ€™t get rent money.  
* A batch retry doubles the payment â†’ Treasury accountants work the weekend.  

HMS-OPS is the **air-traffic control tower** that prevents this chaos.  
It watches *every request*, *every job*, and *every server* in the stack and yells **â€œâš ï¸ turbulence ahead!â€** before a single payment is lost.

---

## 2 â€” Key Concepts in Plain English

| â€œControl-Towerâ€ Word | Think of it asâ€¦ |
|----------------------|-----------------|
| Metric               | A speedometer â€” â€œlatency = 12 sâ€ |
| Log                  | The black box â€” â€œPayment #42 queuedâ€ |
| Trace                | The flight path of **one** request |
| Dashboard            | Radar screen showing live metrics |
| Alert                | Siren that wakes the on-call engineer |
| Runbook              | Emergency checklist â€” â€œIf ACH latency > 5 s â†’ switch to RTPâ€ |
| Incident             | A logged event when SLAs are broken |
| Rollback             | â€œTurn the plane aroundâ€ â€” instantly deploy the last good version |

Keep these eight words handy; the rest of the chapter builds on them.

---

## 3 â€” 60-Second Walk-Through: Add a Metric, Plot It, Alert It

Below is *all* you need to expose **ACH latency** from Laravel, plot it in Grafana, and page the on-call engineer.  

### 3.1  Emit the Metric (Laravel â‰¤ 15 lines)

```php
// app/Services/ACH/Engine.php
use Prometheus\CollectorRegistry;

function recordLatency(float $seconds)
{
    $registry = app(CollectorRegistry::class);
    $timer = $registry->getOrRegisterHistogram(
        'hms', 'ach_latency_seconds', 'ACH rail round-trip time'
    );
    $timer->observe($seconds);
}
```

Explanation  
1. We reuse the **Prometheus PHP client** (installed via Composer).  
2. `ach_latency_seconds` is a **histogram** â€” perfect for latency buckets.  
3. Each `observe()` call is scraped by Prometheus every 15 s.

### 3.2  Ship Logs & Traces (Laravel â‰¤ 10 lines)

```php
// app/Http/Middleware/TrackTrace.php
public function handle($req, $next)
{
    $span = Trace::start('api.request');
    $span->set('route', $req->path());
    $resp = $next($req);
    $span->finish();
    Log::info('req_done', ['route' => $req->path(), 'ms' => $span->duration()]);
    return $resp;
}
```

â€¢ `Trace::start()` opens an OpenTelemetry span.  
â€¢ `Log::info()` writes JSON to **stdout** â€” HMS-OPS tail-ingests it.

### 3.3  Create a Dashboard (Grafana GUI â€“ No Code)

1. Add panel â†’ select metric `hms_ach_latency_seconds_bucket`.  
2. Choose â€œHeatmapâ€ â†’ X-axis *time*, Y-axis *latency bucket*.  
3. Save as **ACH Latency Radar**.

### 3.4  Wire an Alert (YAML â‰¤ 10 lines)

```yaml
# hms-ops/rules/ach_latency.yaml
groups:
- name: ach
  rules:
  - alert: ACHLatencyHigh
    expr: histogram_quantile(0.95,
            rate(hms_ach_latency_seconds_bucket[5m])) > 5
    for: 3m
    labels:
      severity: critical
    annotations:
      runbook: https://runbooks.gov/ops/ach_latency
```

If the 95-th percentile stays above **5 s** for 3 minutes â†’ page `@Treasury_OnCall`.

---

## 4 â€” Flight-Path Under the Hood

```mermaid
sequenceDiagram
    participant APP as HMS-ACH
    participant SCR as Prometheus Scraper
    participant OPS as HMS-OPS AlertMgr
    participant DSH as Grafana Dash
    participant PGR as PagerDuty
    APP-->>SCR: /metrics  (latency 12 s)
    SCR-->>OPS: time-series
    OPS-->>DSH: render panel
    OPS-->>PGR: ğŸ”” ACHLatencyHigh
```

1. **APP** exposes `/metrics`.  
2. **SCR** pulls numbers every 15 s.  
3. **OPS AlertMgr** evaluates rules, sends pages.  
4. **Grafana Dash** shows the red spike.

---

## 5 â€” Inside HMS-OPS (File Tour)

```
hms-ops/
 â”œâ”€ prometheus/            # scrapers + alert rules
 â”‚   â””â”€ prometheus.yml
 â”œâ”€ alertmanager/          # routing to email / PagerDuty
 â”‚   â””â”€ config.yml
 â”œâ”€ loki/                  # log aggregation (Grafana Loki)
 â”œâ”€ tempo/                 # distributed tracing store
 â”œâ”€ dashboards/            # JSON Grafana boards
 â””â”€ runbooks/              # Markdown emergency guides
```

### 5.1  prometheus.yml (â‰¤ 15 lines)

```yaml
scrape_configs:
- job_name: hms
  metrics_path: /metrics
  static_configs:
  - targets: ['ach-svc:9000','api-gw:8080']
```

### 5.2  Alert Routing (â‰¤ 10 lines)

```yaml
# alertmanager/config.yml
receivers:
- name: treasury
  pagerduty_configs:
  - routing_key: ${PAGERDUTY_KEY_TREASURY}
route:
  group_by: ['alertname']
  receiver: treasury
```

---

## 6 â€” Rollbacks & Incidents in One Command

If an alert fires and the runbook says â€œrollback,â€ on-call can run:

```bash
hms-ops rollback ach@v1.8.2
```

The command:

1. Tells Kubernetes to **pin** `hms-ach` to the previous container tag.  
2. Posts a note to the **Incident channel** with the diff.  
3. Closes the PagerDuty incident when latency drops below threshold.

---

## 7 â€” Government Analogy Cheat-Sheet

HMS-OPS Thing      | Real-World Counterpart
-------------------|------------------------
Metric             | Air-traffic radar ping (â€œplane at 30,000 ftâ€)  
Log                | Pilot voice recorder  
Trace              | Flight path drawn on the screen  
Alert              | â€œPull up, pull up!â€ stall warning  
Runbook            | FAA checklist laminated in cockpit  
Rollback           | Divert plane to alternate airport  

---

## 8 â€” Common Beginner Pitfalls

1. **Not exporting metrics on port `/metrics`** â†’ Prometheus errors â€œ`context deadline exceeded`â€.  
2. **Logging plain text** â†’ Loki canâ€™t parse; always use **JSON lines**.  
3. **Forgetting `for: â€¦` in alert rule** â†’ false positives on short spikes.  
4. **Runbook URL 404** â†’ on-call wastes time hunting instructions.  
5. **No trace IDs in logs** â†’ impossible to stitch metrics â†” logs â†” traces.

---

## 9 â€” Mini-Exercise

1. Add `sleep(3)` inside `recordLatency()` to simulate slowness.  
2. Watch **ACH Latency Radar** turn red.  
3. Confirm PagerDuty test event fires after 3 minutes.  
4. Run `hms-ops rollback ach@prev` â€” latency drops â€” alert auto-resolves.  
5. Open the Incident postmortem; note the timeline is auto-filled from logs & traces.

---

## 10 â€” Recap & Whatâ€™s Next

You learned how **HMS-OPS**:

* Collects **metrics, logs, and traces** across the stack.  
* Turns red spikes into **actionable alerts** and links them to **runbooks**.  
* Automates **rollbacks** so downtime stays within SLA.  

But what if the system could *predict* problems **before** they happen?  
Thatâ€™s where we go in [Autonomous Performance Monitor](11_autonomous_performance_monitor_.md).

---

Generated by [AI Codebase Knowledge Builder](https://github.com/The-Pocket/Tutorial-Codebase-Knowledge)